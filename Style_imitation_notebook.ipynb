{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup"
      ],
      "metadata": {
        "id": "W5U2loJioS8X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfSDRvSFnHlz",
        "outputId": "593e6a3f-e97c-48ef-d31c-456c99e19714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset"
      ],
      "metadata": {
        "id": "9IRzlZ_6obcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install datasets -q\n",
        "\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# path to saved HF dataset\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Writing-Style-Transfer-Project/melville300-chaptgpt-pairings\"\n",
        "\n",
        "# Load dataset from Google Drive\n",
        "dataset = load_from_disk(DATASET_PATH)\n",
        "print(f\"Dataset loaded: {dataset}\")\n",
        "\n",
        "import textwrap\n",
        "\n",
        "# Check the dataset structure\n",
        "print(f\"Columns: {dataset.column_names}\")\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "\n",
        "# print sample\n",
        "print(\"Sample: \\n\")\n",
        "print(\"Author: \")\n",
        "print('\\n',dataset[0]['author'],'\\n')\n",
        "print(\"Input: \\n\")\n",
        "print(textwrap.fill(dataset[0]['input'],width=70))\n",
        "print(\"\\nTarget: \\n\")\n",
        "print(dataset[0]['target'])\n",
        "\n"
      ],
      "metadata": {
        "id": "xgQhEOi8oXx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90864974-063b-4ab5-da52-13a8620d42a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset loaded: Dataset({\n",
            "    features: ['input', 'target', 'author'],\n",
            "    num_rows: 320\n",
            "})\n",
            "Columns: ['input', 'target', 'author']\n",
            "Dataset size: 320\n",
            "Sample: \n",
            "\n",
            "Author: \n",
            "\n",
            " Herman Melville \n",
            "\n",
            "Input: \n",
            "\n",
            "My name is Ishmael. Some years ago, when I had little money and no\n",
            "strong interest in staying on land, I decided to go on a sea voyage.\n",
            "This is something I do to improve my mood and health. When I feel\n",
            "depressed, especially to the point where I have troubling thoughts, I\n",
            "see it as necessary to go to sea. This takes the place of more extreme\n",
            "actions. Like the philosopher Cato killing himself, I instead choose\n",
            "to board a ship. Many other people feel the same way about the ocean,\n",
            "even if they do not realize it.\n",
            "\n",
            "Target: \n",
            "\n",
            "Call me Ishmael. Some years ago—never mind how long precisely—having\n",
            "little or no money in my purse, and nothing particular to interest me\n",
            "on shore, I thought I would sail about a little and see the watery part\n",
            "of the world. It is a way I have of driving off the spleen and\n",
            "regulating the circulation. Whenever I find myself growing grim about\n",
            "the mouth; whenever it is a damp, drizzly November in my soul; whenever\n",
            "I find myself involuntarily pausing before coffin warehouses, and\n",
            "bringing up the rear of every funeral I meet; and especially whenever\n",
            "my hypos get such an upper hand of me, that it requires a strong moral\n",
            "principle to prevent me from deliberately stepping into the street, and\n",
            "methodically knocking people’s hats off—then, I account it high time to\n",
            "get to sea as soon as I can. This is my substitute for pistol and ball.\n",
            "With a philosophical flourish Cato throws himself upon his sword; I\n",
            "quietly take to the ship. There is nothing surprising in this. If they\n",
            "but knew it, almost all men in their degree, some time or other,\n",
            "cherish very nearly the same feelings towards the ocean with me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare Model"
      ],
      "metadata": {
        "id": "2ZMwVw0ponpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_name = 'gpt2-medium'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "f8HeI81Hop-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33102bf1-95f4-4404-e66f-4ca9d19eb73f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Format Data"
      ],
      "metadata": {
        "id": "kVs6GNFVot8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_text(example):\n",
        "    author = example['author']\n",
        "    input_text = example['input']\n",
        "    target_text = example['target']\n",
        "\n",
        "    # More explicit format for better learning\n",
        "    formatted = f\"Rewrite the following text in the style of {author}:\\n\\nOriginal: {input_text}\\n\\nRewritten: {target_text}{tokenizer.eos_token}\"\n",
        "    return {'text': formatted}\n",
        "\n",
        "dataset = dataset.map(format_text)\n",
        "print(\"Data formatted!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OR94oyqdouEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6e609f-65ab-442c-e7ea-72c9512b394d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data formatted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Tokenize dataset"
      ],
      "metadata": {
        "id": "gNWahK3Uo9Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512  # Longer sequences for medium model\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names\n",
        ")\n",
        "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])\n",
        "\n",
        "print(\"Data tokenized\")"
      ],
      "metadata": {
        "id": "_UoAUKpGo9UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5bd62b-e47b-44f7-9591-8baf964a7948"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data tokenized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Setup training"
      ],
      "metadata": {
        "id": "sx2I8Pu6pF3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Optimized training for better style transfer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,              # More epochs for better learning\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-5,              # Lower learning rate for more careful learning\n",
        "    logging_steps=25,\n",
        "    save_steps=250,\n",
        "    warmup_steps=200,                # More warmup for stability\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    dataloader_pin_memory=True,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    save_total_limit=2,              # Keep only best checkpoints\n",
        "    load_best_model_at_end=True,     # Load best model at end\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n",
        "\n",
        "# Split dataset\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_test_split['train'],\n",
        "    eval_dataset=train_test_split['test'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"Training setup complete\")\n"
      ],
      "metadata": {
        "id": "bwtRNb2ZpIx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b36506-82f8-4c39-cf1a-095388ca479e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3388378148.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Train Model"
      ],
      "metadata": {
        "id": "Sg0CdJJFv2oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "print(\"This should take 3 minute on T4\")\n",
        "\n",
        "trainer.train()\n",
        "print(\"Training finished!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "cd4Fgp9sv2Cm",
        "outputId": "beb03d9a-15aa-4225-88f2-7cd8eed108ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "This should take 3 minute on T4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [160/160 03:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Save Model"
      ],
      "metadata": {
        "id": "i_XNDdzqxfUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "save_path = '/content/drive/MyDrive/gpt2_medium_style_model'\n",
        "trainer.save_model(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"Model saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjiD-Rmav8U7",
        "outputId": "b2632518-0948-4626-9acf-53759b98833e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/gpt2_medium_style_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_style(input_text, author_name, max_length=80):\n",
        "    prompt = f\"Rewrite the following text in the style of {author_name}:\\n\\nOriginal: {input_text}\\n\\nRewritten:\"\n",
        "\n",
        "    # tokenizer with return_attention_mask to fix warning\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors='pt',\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        return_attention_mask=True\n",
        "    )\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "        model.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            max_length=inputs['input_ids'].shape[1] + max_length,\n",
        "            temperature=0.7,  # Lower temperature for more focused output\n",
        "            do_sample=True,\n",
        "            top_p=0.85,       # Slightly more focused\n",
        "            top_k=40,         # More focused\n",
        "            repetition_penalty=1.2,  # Higher penalty for repetition\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            no_repeat_ngram_size=3  # Prevent 3-gram repetition\n",
        "        )\n",
        "\n",
        "    result = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    # Clean up result - take everything before newlines\n",
        "    result = result.split('\\n')[0].strip()\n",
        "\n",
        "    if result == '':\n",
        "      result = 'No style change'\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "JVldQ-ihxtvH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    # excerpts from moby dick\n",
        "    (\"Manhattan is surrounded by docks, similar to how coral reefs surround islands. Business activity covers it like waves. The streets lead toward the water. At the southern tip is the Battery, where the pier is hit by ocean waves and cooled by sea breezes that were far from land not long ago. Many people are gathered there, watching the water.\", \"Herman Melville\"),\n",
        "    (\"More people are walking straight toward the water, as if preparing to jump in. They do not stop near the buildings for shade. They want to get as close to the water as they can without entering it. Many people stand there, stretching for miles. They come from all directions and different parts of the city. Yet they all gather at the water. Is there something drawing them there, like a magnet attracts a compass needle?\",\"Herman Melville\"),\n",
        "    (\"If you are in an area with lakes, most paths eventually lead downhill to a pool of water. Even someone lost in thought will unknowingly walk toward water if it is nearby. If you are ever thirsty in a desert and traveling with a philosopher, try this as a method to find water. Thought and water are closely connected.\",\"Herman Melville\"),\n",
        "    (\"An artist wants to paint a peaceful and beautiful scene in the Saco valley. He includes trees, fields, animals, a cottage with smoke, and distant mountains. But the image only feels complete if the shepherd in the scene is looking at a stream. In the prairies during June, despite many flowers, something feels missing—there is no water. If Niagara Falls were only sand, people would not visit. A poor poet once had to decide whether to buy a needed coat or spend his money on a trip to the beach. Many healthy boys want to go to sea at some point. On your first sea trip, you may have felt something special when told the ship was out of sight of land. The Persians respected the sea, and the Greeks gave it a god. These reactions suggest something important. The story of Narcissus, who drowned while trying to reach his reflection, symbolizes how we are drawn to an unreachable idea of life, which we also see in bodies of water.\",\"Herman Melville\"),\n",
        "    (\"When I say I go to sea when I feel physically or mentally unwell, I do not mean I travel as a passenger. Passengers need money, and they often get sick and uncomfortable. I also do not go as a high-ranking officer or a cook. I avoid positions of responsibility and prefer not to work hard or take on duties. While I respect good cooking, I do not enjoy doing it myself. Ancient Egyptians preserved animals they cooked, such as ibises and hippopotamuses, which were later found as mummies.\",\"Herman Melville\"),\n",
        "\n",
        "    (\"The sky is blue\",\"Herman Melville\"),\n",
        "    (\"I'm hungry\",\"Herman Melville\"),\n",
        "\n",
        "    # excerpt from frankenstein neutralized\n",
        "     (\"Margaret, I believe I should achieve an important goal. I could have lived a life of comfort and wealth, but I chose to pursue recognition instead. I wish someone would confirm that I have made the right choice. My determination is strong, but my expectations change and I sometimes feel discouraged. I am preparing for a long and difficult journey that will require me to remain strong. I must encourage others and also maintain my own resolve when they are struggling.\",\"Herman Melville\"),\n",
        "    # excerpt from Siddhartha neutralized\n",
        "     (\"After an hour without sleeping, the Brahman got up, walked back and forth, went outside, and saw the moon had risen. He looked into the room through the window and saw Siddhartha standing in the same place with his arms folded and moonlight on his lower legs. The father, feeling concerned, returned to bed.\",\"Herman Melville\"),\n",
        "    # Sports paragraph on the dodgers\n",
        "     (\"Shohei Ohtani, a player for the Los Angeles Dodgers, hit his 40th home run of the season on Saturday in a game against the Toronto Blue Jays, giving the Dodgers a 3-0 lead. The Dodgers won the game 9-1. It was their first consecutive home wins since they defeated the Chicago White Sox in three games from July 1 to July 3. Ohtani’s home run traveled 417 feet to center field.\",\"Herman Melville\")\n",
        "]\n",
        "\n",
        "print(\"\\nSample Tests\\n\")\n",
        "sample_test_results = [generate_style(input_text, author) for input_text, author in test_cases]\n",
        "\n",
        "for i in range(len(test_cases)):\n",
        "\n",
        "    print(textwrap.fill(f\"\\nInput: {test_cases[i][0]}\",width=70))\n",
        "    print(f\"Author: {test_cases[i][1]}\")\n",
        "    print(textwrap.fill(f\"Generated: {sample_test_results[i]}\",width=70))\n",
        "    print('\\n\\n')\n",
        "\n",
        "print(\"\\nStyle transfer complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAw_vu8yyhuD",
        "outputId": "5ea6d73e-bdad-4b51-ef88-de632446caa8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Tests\n",
            "\n",
            " Input: Manhattan is surrounded by docks, similar to how coral reefs\n",
            "surround islands. Business activity covers it like waves. The streets\n",
            "lead toward the water. At the southern tip is the Battery, where the\n",
            "pier is hit by ocean waves and cooled by sea breezes that were far\n",
            "from land not long ago. Many people are gathered there, watching the\n",
            "water.\n",
            "Author: Herman Melville\n",
            "Generated: Now at this point one begins wondering what can be said\n",
            "about a place whose waters rise above its shores? And even if you take\n",
            "into account all the business which surrounds every city on earth,\n",
            "still more than any other sort;—for besides those great harbors or\n",
            "harbours heretofore mentioned,—one may add these seaswardly-placed\n",
            "cities too! It seems as though an island might stand\n",
            "\n",
            "\n",
            "\n",
            " Input: More people are walking straight toward the water, as if\n",
            "preparing to jump in. They do not stop near the buildings for shade.\n",
            "They want to get as close to the water as they can without entering\n",
            "it. Many people stand there, stretching for miles. They come from all\n",
            "directions and different parts of the city. Yet they all gather at the\n",
            "water. Is there something drawing them there, like a magnet attracts a\n",
            "compass needle?\n",
            "Author: Herman Melville\n",
            "Generated: The more he went into his boat-like posture with his arms\n",
            "extended over him on both sides;the greater was that calmness which\n",
            "seemed almost an air of assurance about its source or origin....\n",
            "\n",
            "\n",
            "\n",
            " Input: If you are in an area with lakes, most paths eventually lead\n",
            "downhill to a pool of water. Even someone lost in thought will\n",
            "unknowingly walk toward water if it is nearby. If you are ever thirsty\n",
            "in a desert and traveling with a philosopher, try this as a method to\n",
            "find water. Thought and water are closely connected.\n",
            "Author: Herman Melville\n",
            "Generated: But even though one may be tempted by his own thoughts at\n",
            "times when he wishes for some fresh air or something else from\n",
            "afar—even so far back as where there are no other human beings\n",
            "anywhere near him, yet all that such feelings can accomplish; what\n",
            "would have been done had they not happened? Would any man then wish\n",
            "without hesitation upon entering a lake-streams could get himself out\n",
            "into the\n",
            "\n",
            "\n",
            "\n",
            " Input: An artist wants to paint a peaceful and beautiful scene in the\n",
            "Saco valley. He includes trees, fields, animals, a cottage with smoke,\n",
            "and distant mountains. But the image only feels complete if the\n",
            "shepherd in the scene is looking at a stream. In the prairies during\n",
            "June, despite many flowers, something feels missing—there is no water.\n",
            "If Niagara Falls were only sand, people would not visit. A poor poet\n",
            "once had to decide whether to buy a needed coat or spend his money on\n",
            "a trip to the beach. Many healthy boys want to go to sea at some\n",
            "point. On your first sea trip, you may have felt something special\n",
            "when told the ship was out of sight of land. The Persians respected\n",
            "the sea, and the Greeks gave it a god. These reactions suggest\n",
            "something important. The story of Narcissus, who drowned while trying\n",
            "to reach his reflection, symbolizes how we are drawn to an unreachable\n",
            "idea of life, which we also see in bodies of water.\n",
            "Author: Herman Melville\n",
            "Generated: It comes as much to my mind that one should try for such\n",
            "things; but I am afraid this has been too familiarized by those few\n",
            "examples already mentioned. And yet even these seem somewhat vague\n",
            "enough.—I shall now take up another subject,—the river itself. For\n",
            "here again there seems nothing else except silence upon the waters of\n",
            "the country below us. There is none around me so strikingly silent\n",
            "\n",
            "\n",
            "\n",
            " Input: When I say I go to sea when I feel physically or mentally\n",
            "unwell, I do not mean I travel as a passenger. Passengers need money,\n",
            "and they often get sick and uncomfortable. I also do not go as a high-\n",
            "ranking officer or a cook. I avoid positions of responsibility and\n",
            "prefer not to work hard or take on duties. While I respect good\n",
            "cooking, I do not enjoy doing it myself. Ancient Egyptians preserved\n",
            "animals they cooked, such as ibises and hippopotamuses, which were\n",
            "later found as mummies.\n",
            "Author: Herman Melville\n",
            "Generated: In order that you may know how far I am from my native\n",
            "place—that is,—I will now tell thee why there is no reason for me\n",
            "going ashore at all; but first let us consider what sort o' ship I was\n",
            "then! A man who had once been so well dressed up with his coat about\n",
            "him could hardly be called an ordinary sailor. And yet he has gone\n",
            "some way over\n",
            "\n",
            "\n",
            "\n",
            " Input: The sky is blue\n",
            "Author: Herman Melville\n",
            "Generated: The heavens are blue, and all things\n",
            "\n",
            "\n",
            "\n",
            " Input: I'm hungry\n",
            "Author: Herman Melville\n",
            "Generated: What is my intention?\n",
            "\n",
            "\n",
            "\n",
            " Input: Margaret, I believe I should achieve an important goal. I\n",
            "could have lived a life of comfort and wealth, but I chose to pursue\n",
            "recognition instead. I wish someone would confirm that I have made the\n",
            "right choice. My determination is strong, but my expectations change\n",
            "and I sometimes feel discouraged. I am preparing for a long and\n",
            "difficult journey that will require me to remain strong. I must\n",
            "encourage others and also maintain my own resolve when they are\n",
            "struggling.\n",
            "Author: Herman Melville\n",
            "Generated: What do you think?\n",
            "\n",
            "\n",
            "\n",
            " Input: After an hour without sleeping, the Brahman got up, walked\n",
            "back and forth, went outside, and saw the moon had risen. He looked\n",
            "into the room through the window and saw Siddhartha standing in the\n",
            "same place with his arms folded and moonlight on his lower legs. The\n",
            "father, feeling concerned, returned to bed.\n",
            "Author: Herman Melville\n",
            "Generated: While he lay at last asleep one morning before a lighted\n",
            "lamp there appeared from out some dark recess of another chamber\n",
            "something like this—a small black door behind a desk which was closed\n",
            "by heavy lockers that were left open; but all these locks could be\n",
            "seen when they passed over the threshold. In front stood four men\n",
            "holding their heads as if facing him towards the doorway. One held it\n",
            "slightly\n",
            "\n",
            "\n",
            "\n",
            " Input: Shohei Ohtani, a player for the Los Angeles Dodgers, hit his\n",
            "40th home run of the season on Saturday in a game against the Toronto\n",
            "Blue Jays, giving the Dodgers a 3-0 lead. The Dodgers won the game\n",
            "9-1. It was their first consecutive home wins since they defeated the\n",
            "Chicago White Sox in three games from July 1 to July 3. Ohtani’s home\n",
            "run traveled 417 feet to center field.\n",
            "Author: Herman Melville\n",
            "Generated: This afternoon I made my way into the clubhouse and saw\n",
            "that two players were coming out with bat after batter; one named Sho\n",
            "Ha Noi—who has been playing this year among other things for\n",
            "Liverpool,—and another called him 'Sho' Hokun.' One by he means\n",
            "Ahimself, as it is said at all places where there are many Japanese\n",
            "people living now. And then an English\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Style transfer complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Evaluation Metrics"
      ],
      "metadata": {
        "id": "_n-FgYAExtA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk rouge-score -q\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "rouge = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def calculate_perplexity(text):\n",
        "    \"\"\"Calculate perplexity using the trained model\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
        "        loss = outputs.loss\n",
        "        perplexity = torch.exp(loss).item()\n",
        "\n",
        "    return perplexity\n",
        "\n",
        "def simple_evaluation_metrics(test_cases):\n",
        "    \"\"\"Evaluate using BLEU, ROUGE, and Perplexity\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"BLEU | ROUGE | PERPLEXITY EVALUATION\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    bleu_scores = []\n",
        "    rouge1_scores = []\n",
        "    rougeL_scores = []\n",
        "    perplexities = []\n",
        "\n",
        "    for i, (input_text, author) in enumerate(test_cases):\n",
        "        generated = generate_style(input_text, author)\n",
        "\n",
        "        # BLEU Score (generated vs original)\n",
        "        input_tokens = nltk.word_tokenize(input_text.lower())\n",
        "        generated_tokens = nltk.word_tokenize(generated.lower())\n",
        "        bleu = sentence_bleu([input_tokens], generated_tokens)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        # ROUGE Scores (generated vs original)\n",
        "        rouge_scores = rouge.score(input_text, generated)\n",
        "        rouge1 = rouge_scores['rouge1'].fmeasure\n",
        "        rougeL = rouge_scores['rougeL'].fmeasure\n",
        "        rouge1_scores.append(rouge1)\n",
        "        rougeL_scores.append(rougeL)\n",
        "\n",
        "        # Perplexity (how natural/fluent the generated text is)\n",
        "        ppl = calculate_perplexity(generated)\n",
        "        perplexities.append(ppl)\n",
        "\n",
        "        print(f\"\\nTest {i+1}:\")\n",
        "        print(f\"Input:     {input_text[:60]}...\")\n",
        "        print(f\"Generated: {generated}\")\n",
        "        print(f\"BLEU:      {bleu:.3f}\")\n",
        "        print(f\"ROUGE-1:   {rouge1:.3f}\")\n",
        "        print(f\"ROUGE-L:   {rougeL:.3f}\")\n",
        "        print(f\"Perplexity: {ppl:.1f}\")\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "    avg_rouge1 = np.mean(rouge1_scores)\n",
        "    avg_rougeL = np.mean(rougeL_scores)\n",
        "    avg_perplexity = np.mean(perplexities)\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(\"AVERAGE SCORES\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"BLEU Score:     {avg_bleu:.3f}\")\n",
        "    print(f\"ROUGE-1 Score:  {avg_rouge1:.3f}\")\n",
        "    print(f\"ROUGE-L Score:  {avg_rougeL:.3f}\")\n",
        "    print(f\"Perplexity:     {avg_perplexity:.1f}\")\n",
        "\n",
        "    # Simple interpretation\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(\"INTERPRETATION\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if avg_bleu < 0.3:\n",
        "        print(\"✅ Good style change (low BLEU)\")\n",
        "    else:\n",
        "        print(\"⚠️  Limited style change (high BLEU)\")\n",
        "\n",
        "    if avg_rouge1 > 0.3:\n",
        "        print(\"✅ Content preserved (good ROUGE)\")\n",
        "    else:\n",
        "        print(\"⚠️  Content may be lost (low ROUGE)\")\n",
        "\n",
        "    if avg_perplexity < 50:\n",
        "        print(\"✅ Fluent text (low perplexity)\")\n",
        "    else:\n",
        "        print(\"⚠️  Text may be unnatural (high perplexity)\")\n",
        "\n",
        "# Run evaluation\n",
        "simple_evaluation_metrics(test_cases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eO9wm7Lwgp4",
        "outputId": "9f7c762e-0799-4442-8eed-fa24b7d3136d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "BLEU | ROUGE | PERPLEXITY EVALUATION\n",
            "==================================================\n",
            "\n",
            "Test 1:\n",
            "Input:     Manhattan is surrounded by docks, similar to how coral reefs...\n",
            "Generated: As if a great mariner with his ship at anchor near this place might have been foretold about as he was approaching its shores, so on account should we now look into every part or section within our city; for such places may be counted upon to receive these tides, which would render them no longer seaward but rather inland—like those mighty swells they call seas--and thus furnish us\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.076\n",
            "ROUGE-L:   0.046\n",
            "Perplexity: 74.1\n",
            "\n",
            "Test 2:\n",
            "Input:     More people are walking straight toward the water, as if pre...\n",
            "Generated: The more men who now approach the sea-shore, some on foot or by other — these were those that had been drawn into this great gathering; but then came upon\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.075\n",
            "ROUGE-L:   0.057\n",
            "Perplexity: 110.2\n",
            "\n",
            "Test 3:\n",
            "Input:     If you are in an area with lakes, most paths eventually lead...\n",
            "Generated: But when I was going out on my errand into some unknown country, not knowing where or how\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.000\n",
            "ROUGE-L:   0.000\n",
            "Perplexity: 27.6\n",
            "\n",
            "Test 4:\n",
            "Input:     An artist wants to paint a peaceful and beautiful scene in t...\n",
            "Generated: So much for that picture-painting thing! I am going away from home. Not yet; but here comes my old friend, Bartleby, painting up this river under one cloud, so as scarcely show\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.039\n",
            "ROUGE-L:   0.020\n",
            "Perplexity: 72.8\n",
            "\n",
            "Test 5:\n",
            "Input:     When I say I go to sea when I feel physically or mentally un...\n",
            "Generated: At that time I went ashore with my shipmates; but now I am no longer so inclined. For one thing—my master was gone off from his office at night, and there being nothing for me here except water,—I had nothing else left besides salt and bread than what we carried along into the land.\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.082\n",
            "ROUGE-L:   0.082\n",
            "Perplexity: 50.7\n",
            "\n",
            "Test 6:\n",
            "Input:     The sky is blue...\n",
            "Generated: ‘The skies are blue,’ so that it's clear\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.462\n",
            "ROUGE-L:   0.462\n",
            "Perplexity: 346.9\n",
            "\n",
            "Test 7:\n",
            "Input:     I'm hungry...\n",
            "Generated: Ah, but what do you want?\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.000\n",
            "ROUGE-L:   0.000\n",
            "Perplexity: 63.9\n",
            "\n",
            "Test 8:\n",
            "Input:     Margaret, I believe I should achieve an important goal. I co...\n",
            "Generated: Now it seems good to do something about this situation; perhaps if you may say so, then you can give some assurance as well? No matter what your personal circumstances may be—my mind has always been very keen on doing anything at all which might help those who were under such great distress from old age. But now we shall both know our place among mankind,—a little better off than before!\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.052\n",
            "ROUGE-L:   0.052\n",
            "Perplexity: 36.9\n",
            "\n",
            "Test 9:\n",
            "Input:     After an hour without sleeping, the Brahman got up, walked b...\n",
            "Generated: Now that they were all asleep again—with no more sleep than before; then he took a step towards them as if from curiosity or for some other reason.—And seeing him there stood sitting erect at their table-bench,—the young man looking straight down upon him like one who is going out alone now after dark! And so it was done both by himself (as though nothing could be further from\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.126\n",
            "ROUGE-L:   0.079\n",
            "Perplexity: 52.3\n",
            "\n",
            "Test 10:\n",
            "Input:     Shohei Ohtani, a player for the Los Angeles Dodgers, hit his...\n",
            "Generated: Now this afternoon at noon I heard that there had been a scoreless inning between two teams here yesterday and today; but as soon then as my eyes were drawn over it again I began thinking how many more like them would have gone down by now if not such an incident happened! And yet some things happen which are beyond our power to control—and though we cannot know what is going upon with these\n",
            "BLEU:      0.000\n",
            "ROUGE-1:   0.040\n",
            "ROUGE-L:   0.040\n",
            "Perplexity: 35.5\n",
            "\n",
            "==================================================\n",
            "AVERAGE SCORES\n",
            "==================================================\n",
            "BLEU Score:     0.000\n",
            "ROUGE-1 Score:  0.095\n",
            "ROUGE-L Score:  0.084\n",
            "Perplexity:     87.1\n",
            "\n",
            "==================================================\n",
            "INTERPRETATION\n",
            "==================================================\n",
            "✅ Good style change (low BLEU)\n",
            "⚠️  Content may be lost (low ROUGE)\n",
            "⚠️  Text may be unnatural (high perplexity)\n"
          ]
        }
      ]
    }
  ]
}